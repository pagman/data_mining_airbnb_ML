{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Εξόρυξη δεδομένων"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Αλίκη Τσαμοπούλου Δαμιανή sdi1900193 \\\n",
    "Παναγιώτης Μαντάς sdi1400294\n",
    "---\n",
    "\n",
    "Η άσκηση έγινε με το VS code και python 3.10.14\\\n",
    "Η πιο συμαντική παραδοχή που πείραμε μετά απο συζήτη στο eclass είναι ότι στο αρχείο listings δεν υπάρχουν πολλαπλότυπα,\\\n",
    "πράγμα που στην πραγματικότητα δεν συμβαίνει καθώς ενώνοντας τα δεδομένα μέσα στο αρχείο μπορεί να υπάρχουν, \n",
    "διπλότυπα ή και πολλαπλότυπα.\\\n",
    "Αυτό έχει ως αποτέλεσμα να επηρεάζει την ακρίβεια των αποτελεσμάτων.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Δήλωση βιβλιοθηκών"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 11:40:00.780676: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-06-05 11:40:00.830340: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-05 11:40:00.830378: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-05 11:40:00.831649: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-06-05 11:40:00.838845: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-06-05 11:40:02.057863: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from scipy.interpolate import interp1d\n",
    "import folium\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import Counter\n",
    "import math\n",
    "from langdetect import detect\n",
    "from transformers import pipeline\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=pd.errors.DtypeWarning)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Δήλωση Σταθερών"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_TRAINING_DATASET_SIZE = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Προεπεξεργασία"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Προετοιμασία των reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Φόρτωση στη μνήμη"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = {\n",
    "    \"2019\": [],\n",
    "    \"2023\": [],\n",
    "}\n",
    "\n",
    "file_path_2019 = f'2019/april/reviews.csv'\n",
    "file_path_2023 = f'2023/september/reviews.csv'\n",
    "    \n",
    "reviews[\"2019\"] = pd.read_csv(file_path_2019)\n",
    "reviews[\"2023\"] = pd.read_csv(file_path_2023)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Φιλτράρισμα γνωρισμάτων"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes on load: \n",
      "(287433, 2)\n",
      "(579991, 2)\n",
      "Data saved to output\n"
     ]
    }
   ],
   "source": [
    "filter_columns = {\n",
    "    \"2019\": [\n",
    "        'id', 'comments'\n",
    "    ],\n",
    "    \"2023\": [\n",
    "        'id', 'comments'\n",
    "    ]\n",
    "}\n",
    "\n",
    "working_datasets_reviews = {\n",
    "    \"2019\": [],\n",
    "    \"2023\": []\n",
    "}\n",
    "\n",
    "print(\"Shapes on load: \")\n",
    "\n",
    "for year, dataset in reviews.items():\n",
    "    working_datasets_reviews[year] = reviews[year][filter_columns[year]]\n",
    "    working_datasets_reviews[year].reset_index(drop=True, inplace=True)\n",
    "\n",
    "    print(working_datasets_reviews[year].shape)\n",
    "\n",
    "    working_datasets_reviews[year].to_csv(f'output/train_{year}.csv', quoting=csv.QUOTE_NONNUMERIC, quotechar='\"', escapechar='\\\\', encoding=\"utf-8\", index=False, doublequote=False)\n",
    "\n",
    "print(\"Data saved to output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Στα δεδομένα περνάμε και την στήλη neighouhood_cleansed διότι σε αυτή την στήλη είναι ήδη καθαρισμένα τα δεδομένα.\\\n",
    "Φτιάχνουμε και το αρχείο που ζητήθηκε train_2019. \\\n",
    "Φτιάχνουμε και μια στήλη month για να μπορούμε αργότερα να ξέρουμε απο πιο μήνα προήλθαν τα δεδομένα.\\\n",
    "\n",
    "Στο πεδίο price αφαιρέσαμε το σύμβολο του δολλαρίου και αφαιρέσαμε το , ώστε να περάσει ως αριθμός στο panda και να μπορούμε να το χειριστούμε αναλόγος"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Προσθήκη γνωρίσματος sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31316/3584559531.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset.loc[:,'sentiment'] = None\n",
      "/tmp/ipykernel_31316/3584559531.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset.loc[:,'sentiment'] = None\n"
     ]
    }
   ],
   "source": [
    "for year, dataset in working_datasets_reviews.items():\n",
    "    dataset.loc[:,'sentiment'] = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Επιλογή πλειάδων που είναι σε αγγλικά"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes before cleaning empty rows: \n",
      "2019 (500, 3)\n",
      "2023 (500, 3)\n",
      "Shapes after cleaning empty rows: \n",
      "2019 (405, 3)\n",
      "2023 (354, 3)\n"
     ]
    }
   ],
   "source": [
    "# Function to check if a column name is in English\n",
    "def is_english(column_name):\n",
    "    try:\n",
    "        return detect(column_name) == 'en'\n",
    "    except:\n",
    "        return False\n",
    "    \n",
    "cleaned_datasets_reviews = {\n",
    "    \"2019\": [],\n",
    "    \"2023\": []\n",
    "}\n",
    "\n",
    "print(\"Shapes before cleaning empty rows: \")\n",
    "\n",
    "# ------------------for development ####\n",
    "for year, dataset in working_datasets_reviews.items():\n",
    "    working_datasets_reviews[year] = dataset.sample(500, replace=False)    \n",
    "# ------------------------------\n",
    "\n",
    "for year, dataset in working_datasets_reviews.items():\n",
    "    print(year, dataset.shape)\n",
    "\n",
    "for year, dataset in working_datasets_reviews.items():\n",
    "    df = dataset.dropna(subset=['comments'])  # Specify columns to check for empty strings\n",
    "\n",
    "    df_filtered = df[df['comments'].apply(is_english)]\n",
    "    \n",
    "    cleaned_datasets_reviews[year] = df_filtered\n",
    "\n",
    "\n",
    "print(\"Shapes after cleaning empty rows: \")\n",
    "\n",
    "for year, dataset in cleaned_datasets_reviews.items():\n",
    "    print(year, dataset.shape)\n",
    "\n",
    "    dataset.to_csv(f'output/reviews_{year}_english.csv', quoting=csv.QUOTE_NONNUMERIC, quotechar='\"', escapechar='\\\\', encoding=\"utf-8\", index=False, doublequote=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Προετοιμασία των listings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019 ['april']\n",
      "Dimensions for  2019/april/listings.csv  are  (9661, 107)\n",
      "2023 ['september']\n",
      "Dimensions for  2023/september/listings.csv  are  (12955, 76)\n",
      "Dataset 2019 shape:  (9661, 107)\n",
      "Dataset 2023 shape:  (12955, 76)\n",
      "Data loaded\n"
     ]
    }
   ],
   "source": [
    "month_map = {\n",
    "    \"2019\": ['april'],\n",
    "    \"2023\": ['september'],\n",
    "}\n",
    "\n",
    "complete_datasets_listings = {\n",
    "    \"2019\": [],\n",
    "    \"2023\": []\n",
    "}\n",
    "\n",
    "\n",
    "for year, months in month_map.items():\n",
    "    print(year, months)\n",
    "\n",
    "    data_frames = []\n",
    "\n",
    "    for month in months:\n",
    "        file_path = f'{year}/{month}/listings.csv'\n",
    "        df = pd.read_csv(file_path)\n",
    "        df['month'] = month\n",
    "        data_frames.append(df)\n",
    "        print(\"Dimensions for \" , file_path, \" are \" , df.shape)\n",
    "\n",
    "        df.to_csv(f'output/{year}_{month}_listings.csv', index=False)\n",
    "\n",
    "    complete_datasets_listings[year] = pd.concat(data_frames, ignore_index=True)\n",
    "    complete_datasets_listings[year].reset_index(drop=True, inplace=True)\n",
    "\n",
    "for year, dataset in complete_datasets_listings.items():\n",
    "    print(\"Dataset\", year, \"shape: \", complete_datasets_listings[year].shape)\n",
    "\n",
    "print(\"Listings data loaded\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Φιλτράρισμα γνωρισμάτων στο listings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 2019 Total columns:  3\n",
      "(9661, 3)\n",
      "Year 2023 Total columns:  3\n",
      "(12955, 3)\n",
      "Data saved to output\n"
     ]
    }
   ],
   "source": [
    "filter_columns = {\n",
    "    \"2019\": [\n",
    "        'id', 'review_scores_rating', 'number_of_reviews'\n",
    "    ],\n",
    "    \"2023\": [\n",
    "        'id', 'review_scores_rating', 'number_of_reviews'\n",
    "    ]\n",
    "}\n",
    "\n",
    "working_datasets_listings = {\n",
    "    \"2019\": [],\n",
    "    \"2023\": []\n",
    "}\n",
    "\n",
    "for year, dataset in complete_datasets_listings.items():\n",
    "    working_datasets_listings[year] = complete_datasets_listings[year][filter_columns[year]]\n",
    "    working_datasets_listings[year].reset_index(drop=True, inplace=True)\n",
    "\n",
    "    print(\"Year\", year, \"Total columns: \", len(filter_columns[year]))\n",
    "    print(working_datasets_listings[year].shape)\n",
    "\n",
    "    working_datasets_listings[year].to_csv(f'output/train_{year}.csv', quoting=csv.QUOTE_NONNUMERIC, quotechar='\"', escapechar='\\\\', encoding=\"utf-8\", index=False, doublequote=False)\n",
    "\n",
    "print(\"Data saved to output\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ταξινόμηση βάσει review_scores_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>review_scores_rating</th>\n",
       "      <th>number_of_reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9002</th>\n",
       "      <td>32706562</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8962</th>\n",
       "      <td>32654936</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1883</th>\n",
       "      <td>14152595</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7740</th>\n",
       "      <td>30192195</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3121</th>\n",
       "      <td>19104215</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3101</th>\n",
       "      <td>19047757</td>\n",
       "      <td>100.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3098</th>\n",
       "      <td>19041864</td>\n",
       "      <td>100.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3082</th>\n",
       "      <td>19002022</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3128</th>\n",
       "      <td>19126329</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9582</th>\n",
       "      <td>33646553</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7264 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  review_scores_rating  number_of_reviews\n",
       "9002  32706562                  20.0                  1\n",
       "8962  32654936                  20.0                  1\n",
       "1883  14152595                  20.0                  1\n",
       "7740  30192195                  20.0                  1\n",
       "3121  19104215                  20.0                  1\n",
       "...        ...                   ...                ...\n",
       "3101  19047757                 100.0                  8\n",
       "3098  19041864                 100.0                  7\n",
       "3082  19002022                 100.0                  1\n",
       "3128  19126329                 100.0                  1\n",
       "9582  33646553                 100.0                  1\n",
       "\n",
       "[7264 rows x 3 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for year, dataset in working_datasets_listings.items():\n",
    "    working_datasets_listings[year] = working_datasets_listings[year].dropna()\n",
    "    working_datasets_listings[year] = working_datasets_listings[year].sort_values(by='review_scores_rating', ascending=True)\n",
    "\n",
    "working_datasets_listings['2019']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 2019\n",
      "Positive shape:  (100, 3)\n",
      "Negative shape:  (100, 3)\n",
      "Year 2023\n",
      "Positive shape:  (100, 3)\n",
      "Negative shape:  (100, 3)\n"
     ]
    }
   ],
   "source": [
    "working_datasets_listings_positive = {\n",
    "    \"2019\": [],\n",
    "    \"2023\": []\n",
    "}\n",
    "\n",
    "working_datasets_listings_negative = {\n",
    "    \"2019\": [],\n",
    "    \"2023\": []\n",
    "}\n",
    "\n",
    "\n",
    "for year, dataset in working_datasets_listings.items():\n",
    "    working_datasets_listings_positive[year] = working_datasets_listings[year].head(TARGET_TRAINING_DATASET_SIZE//2)\n",
    "    working_datasets_listings_negative[year] = working_datasets_listings[year].tail(TARGET_TRAINING_DATASET_SIZE//2)\n",
    "\n",
    "    print(\"Year\", year)\n",
    "    print(\"Positive shape: \", working_datasets_listings_positive[year].shape)\n",
    "    print(\"Negative shape: \", working_datasets_listings_negative[year].shape)\n",
    "\n",
    "\n",
    "# TODO:\n",
    "\n",
    "-- find listing ids\n",
    "-- find reviews of those listing ids\n",
    "-- predict sentiment for those listing ids\n",
    "-- create a subset for each prediction\n",
    "-- merdge subsets\n",
    "-- save the subset for the next step...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Σΰνθεση του τελικού αρχείου εκπαίδευσης"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Ένωση των 2/3 αρχείων που θα έχουν εγγραφές ανά συναίσθημα"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes after sampling: \n",
      "2019 (200, 3)\n",
      "2023 (200, 3)\n"
     ]
    }
   ],
   "source": [
    "sample_datasets = {\n",
    "    \"2019\": [],\n",
    "    \"2023\": []\n",
    "}\n",
    "\n",
    "for year, dataset in cleaned_datasets_reviews.items():\n",
    "    sample_datasets[year] = dataset.sample(200, replace=False)\n",
    "\n",
    "\n",
    "print(\"Shapes after sampling: \")\n",
    "\n",
    "for year, dataset in sample_datasets.items():\n",
    "    print(year, dataset.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Προσθήκη γνωρίσματος cleansed_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_datasets_cleansed = {\n",
    "    \"2019\": [],\n",
    "    \"2023\": []\n",
    "}\n",
    "\n",
    "for year, dataset in sample_datasets.items():\n",
    "    dataset.loc[:,'cleansed_comments'] = dataset.loc[:,'comments']\n",
    "    sample_datasets_cleansed[year] = dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Υπολογισμός συνόλου με bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Προεπεξεργασία πεδίου comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLEANR = re.compile('<.*?>') #remove html tags\n",
    "pattern = r'\\b\\d+m2\\b' # remove apartment size\n",
    "special = r'[-!@#$%^&*()_+={}\\[\\]:;\"\\'|<,>.?/~`]' # remove special character\n",
    "symbols = re.compile(\"[\"\n",
    "                     u\"\\U0001F600-\\U0001F64F\"  # Emoticons\n",
    "                     u\"\\U0001F300-\\U0001F5FF\"  # Symbols & pictographs\n",
    "                     u\"\\U0001F680-\\U0001F6FF\"  # Transport & map symbols\n",
    "                     u\"\\U0001F1E0-\\U0001F1FF\"  # Flags (iOS)\n",
    "                     u\"\\U00002500-\\U00002BEF\"  # Chinese/Japanese/Korean characters\n",
    "                     u\"\\U00002702-\\U000027B0\"\n",
    "                     u\"\\U00002702-\\U000027B0\"\n",
    "                     u\"\\U000024C2-\\U0001F251\"\n",
    "                     u\"\\U0001f926-\\U0001f937\"\n",
    "                     u\"\\U00010000-\\U0010ffff\"\n",
    "                     u\"\\u2640-\\u2642\"\n",
    "                     u\"\\u2600-\\u2B55\"\n",
    "                     u\"\\u200d\"\n",
    "                     u\"\\u23cf\"\n",
    "                     u\"\\u23e9\"\n",
    "                     u\"\\u231a\"\n",
    "                     u\"\\ufe0f\"  # dingbats\n",
    "                     u\"\\u3030\"\n",
    "                     \"]+\", re.UNICODE)\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word.lower() not in STOPWORDS]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "def cleanUp(field):\n",
    "    if field == None:\n",
    "        return \"\"\n",
    "    field = field.lower()\n",
    "    field = re.sub(CLEANR, ' ', field)\n",
    "    # HTTP/HTTPS\n",
    "    # HASHTAGS\n",
    "\n",
    "    field = re.sub(r'[^\\w\\s]', ' ', field) # Remove punctuation\n",
    "    field = re.sub(r'\\d+', ' ', field) # Remove digits\n",
    "    field = re.sub(r'\\s+', ' ', field).strip() # Remove extra whitespaces\n",
    "    field = re.sub(r'\\b\\w\\b', ' ', field) # Remove single letters\n",
    "    field = re.sub(pattern, ' ', field) #remove appartment sizes\n",
    "    field = re.sub(r'\\b\\w{2}\\b', ' ', field) #remove 2 letter words\n",
    "    field = re.sub(symbols, '', field)\n",
    "    field = re.sub(special, '', field)\n",
    "    field = remove_stopwords(field)\n",
    "    return field\n",
    "\n",
    "for year, dataset in sample_datasets_cleansed.items():    \n",
    "    for index, row in dataset.iterrows():\n",
    "        dataset.at[index, 'cleansed_comments'] = cleanUp(row['cleansed_comments'])\n",
    "\n",
    "        dataset.to_csv(f'output/train_{year}_sample_cleansed.csv', quoting=csv.QUOTE_NONNUMERIC, quotechar='\"', escapechar='\\\\', encoding=\"utf-8\", index=False, doublequote=False)\n",
    "\n",
    "d1 = sample_datasets_cleansed['2019']\n",
    "d2 = sample_datasets_cleansed['2023']        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ανάλυση συναισθημάτων"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFDistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of TFDistilBertForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline(model=\"lxyuan/distilbert-base-multilingual-cased-sentiments-student\",  return_all_scores=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'label': 'positive', 'score': 0.45254042744636536},\n",
       "  {'label': 'neutral', 'score': 0.2954728901386261},\n",
       "  {'label': 'negative', 'score': 0.25198668241500854}]]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"The book is on the table.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
